<h1 align="center">Trabalho Pr√°tico IA [Algoritmos] (2025/2)</h1>

<div align="center">

![Python](https://img.shields.io/badge/python-blue?style=for-the-badge&logo=python&logoColor=white)
![VS Code](https://img.shields.io/badge/visual%20studio%20code-blue?style=for-the-badge)
![Ubuntu](https://img.shields.io/badge/ubuntu-orange?style=for-the-badge&logo=ubuntu&logoColor=white)

üìñ:
[Vis√£o Geral](#vis√£o-geral) |
[Como reproduzir](#como-reproduzir) |
[Decis√µes T√©cnicas](#decis√µes-t√©cnicas)

</div>


## Vis√£o Geral

<div align="justify">
O objetivo do trabalho, realizado na disciplina de Intelig√™ncia Artificial ofertada pelo professor Tiago Aves de Oliveira, foi de compreender, implementar e comparar algoritmos cl√°ssicos de IA e Computa√ß√£o Natural, preparando e analisando dados reais.
</div>

### Partes do trabalho:
O trabalho foi dividido em quatro partes:

- Parte 1 - √Årvore de decis√£o manual
- Parte 2 - Supervisionado (Kaggle/UCI): KNN, SVM e √Årvore 
- Parte 3 - Algoritmo Gen√©tico (AG)
- Parte 4 - Enxame e Imunes

<!--
### Estrutura do Reposit√≥rio:
```
TRABALHO PR√ÅTICO IA/
‚îÇ   .gitattributes
‚îÇ   README.md
‚îÇ   requirements.txt
‚îÇ   svm.model
‚îÇ   
‚îú‚îÄ‚îÄ‚îÄdata
‚îÇ   ‚îú‚îÄ‚îÄ‚îÄprocessed
‚îÇ   ‚îÇ       benchmark_results.csv
‚îÇ   ‚îÇ       comparison_report.txt
‚îÇ   ‚îÇ       confusion_matrix_dt_100000.png
‚îÇ   ‚îÇ       confusion_matrix_knn_100000.png
‚îÇ   ‚îÇ       confusion_matrix_svm_100000.png
‚îÇ   ‚îÇ       decision_tree_visualization.png
‚îÇ   ‚îÇ       decision_tree_visualization_100000.png
‚îÇ   ‚îÇ       X_test.csv
‚îÇ   ‚îÇ       X_test_scaled.csv
‚îÇ   ‚îÇ       X_train.csv
‚îÇ   ‚îÇ       X_train_scaled.csv
‚îÇ   ‚îÇ       y_test.csv
‚îÇ   ‚îÇ       y_train.csv
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄraw
‚îÇ           Watera.csv
‚îÇ
‚îî‚îÄ‚îÄ‚îÄsrc
    ‚îú‚îÄ‚îÄ‚îÄpart1_tree_manual
    ‚îÇ       tree_diagram.md
    ‚îÇ       tree_image.png
    ‚îÇ       tree_manual.py
    ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄpart2_ml
    ‚îÇ   ‚îÇ   preprocess.py
    ‚îÇ   ‚îÇ   train_knn.py
    ‚îÇ   ‚îÇ   train_svm.py
    ‚îÇ   ‚îÇ   train_tree.py
    ‚îÇ   ‚îÇ   util_metrics.py
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ__pycache__
    ‚îÇ           preprocess.cpython-310.pyc
    ‚îÇ           preprocess.cpython-311.pyc
    ‚îÇ           util_metrics.cpython-310.pyc
    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄpart3_ga
            ga.py
```
-->
<!--
```
TREE-DECISION/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                    # Dados brutos
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ plant_growth_data.csv
‚îÇ   ‚îî‚îÄ‚îÄ processed/              # Dados processados
‚îÇ       ‚îú‚îÄ‚îÄ X_train.csv         # Features de treino (sem escalonamento)
‚îÇ       ‚îú‚îÄ‚îÄ X_train_scaled.csv  # Features de treino (escalonadas)
‚îÇ       ‚îú‚îÄ‚îÄ y_train.csv         # Target de treino
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ part1_tree_manual/      # Implementa√ß√£o manual
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tree_manual.py      # Classe Tree customizada [Exemplo: 32 correntes filos√≥ficas]
‚îÇ   ‚îÇ   
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ part2_ml/               # Machine Learning
‚îÇ       ‚îú‚îÄ‚îÄ preprocess.py       # Pr√©-processamento completo
‚îÇ       ‚îú‚îÄ‚îÄ train_tree.py       # Treinar Decision Tree
‚îÇ       ‚îú‚îÄ‚îÄ train_knn.py        # Treinar KNN
‚îÇ       ‚îú‚îÄ‚îÄ train_svm.py        # Treinar SVM
‚îÇ       ‚îî‚îÄ‚îÄ util_metrics.py     # Fun√ß√µes de m√©tricas
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt            # Depend√™ncias
‚îî‚îÄ‚îÄ README.md                   # Este arquivo
```
-->

<!--
Este projeto explora **√Årvores de Decis√£o** de duas formas:

1. **Parte 1 - Implementa√ß√£o Manual (`src/part1_tree_manual/`)**
   - Estrutura de dados de √°rvore bin√°ria do zero
   - Visualiza√ß√£o com NetworkX e Matplotlib
   - Exemplo: √Årvore de decis√£o filos√≥fica com 32 correntes (6 n√≠veis)

2. **Parte 2 - Machine Learning (`src/part2_ml/`)**
   - Pr√©-processamento robusto de dados
   - Treinamento de modelos: Decision Tree, KNN, SVM
   - M√©tricas de avalia√ß√£o e valida√ß√£o cruzada 
-->



## Como reproduzir

### Pr√©-requisitos

- **Python 3.8+** instalado
- **pip** (gerenciador de pacotes Python)
- **Git** (opcional, para clonar o reposit√≥rio)

---

### Instala√ß√£o R√°pida

#### Usando run.sh (Linux):
```bash
# Concede permiss√µes de execu√ß√£o:
chmod +x run.sh

# Cria .venv e baixa depen√™ncias nele:
./run.sh
```

#### Usando Makefile (Alternativa):

```bash
# Instalar depend√™ncias
make install

# Executar Parte 1 (√Årvore Manual Filos√≥fica)
make part1

# Executar Parte 2 completa (ML: pr√©-processamento + treinos)
make part2

# Ou executar partes espec√≠ficas:
make part2-dt         # Apenas Decision Tree
make part2-knn        # Apenas KNN
make part2-svm        # Apenas SVM

# Executar Parte 3 (Algoritmo Gen√©tico)
make part3

# Executar Parte 4 (Enxame e Imunes)
make part4              # Executa ACO e CLONALG
make part4-aco          # Apenas ACO vs GA
make part4-clonalg      # Apenas CLONALG vs ACO vs GA

# Ver resultados
make results

# Limpar arquivos gerados
make clean
```

#### Instala√ß√£o Manual

```bash
pip install -r requirements.txt
```

---

### Bibliotecas Utilizadas

| Biblioteca | Vers√£o | Por Que Usamos? | Decis√£o de Implementa√ß√£o |
|------------|--------|-----------------|--------------------------|
| **pandas** | 2.1.4 | Manipula√ß√£o de dados tabulares (CSV, DataFrames) | Escolhido por sua efici√™ncia em opera√ß√µes de leitura/escrita de CSV e transforma√ß√µes de dados. A API intuitiva permite opera√ß√µes complexas em uma linha. |
| **numpy** | 1.26.3 | Opera√ß√µes num√©ricas eficientes (arrays, matrizes) | Base para computa√ß√£o cient√≠fica em Python. Vetoriza√ß√£o de opera√ß√µes acelera c√°lculos em 10-100x comparado a loops Python puros. |
| **scikit-learn** | 1.3.2 | **Biblioteca principal de ML**: Decision Tree, KNN, SVM, pr√©-processamento, m√©tricas | API consistente entre algoritmos facilita experimenta√ß√£o. Implementa√ß√µes otimizadas em C/Cython garantem performance. Amplamente testada e documentada. |
| **scipy** | 1.11.4 | Algoritmos cient√≠ficos e estat√≠sticos (depend√™ncia do scikit-learn) | Fornece estruturas de dados especializadas (sparse matrices) e algoritmos de otimiza√ß√£o usados internamente pelo scikit-learn. |
| **matplotlib** | 3.8.2 | Visualiza√ß√£o de dados (gr√°ficos, plots) | Padr√£o *de facto* para visualiza√ß√£o cient√≠fica em Python. Flexibilidade para customiza√ß√£o detalhada de gr√°ficos. |
| **seaborn** | 0.13.0 | Visualiza√ß√£o estat√≠stica (matriz de confus√£o) | Built on top do matplotlib, oferece temas visuais mais modernos e fun√ß√µes especializadas para an√°lise estat√≠stica. |

---

<!--
### Sobre a escolha de cada Biblioteca

#### **scikit-learn** 
```python
# Modelos de ML
from sklearn.tree import DecisionTreeClassifier       # √Årvore de Decis√£o
from sklearn.neighbors import KNeighborsClassifier    # KNN
from sklearn.svm import SVC                           # SVM

# Pr√©-processamento
from sklearn.preprocessing import StandardScaler      # Escalonamento (KNN/SVM)
from sklearn.preprocessing import LabelEncoder        # String ‚Üí N√∫mero

# M√©tricas e Valida√ß√£o
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.model_selection import train_test_split, cross_val_score
```

#### **pandas** + **numpy**
```python
import pandas as pd    # Ler CSV, manipular tabelas
import numpy as np     # Opera√ß√µes matem√°ticas r√°pidas
```
-->

## Decis√µes T√©cnicas

### **Parte 1: √Årvore Manual (Filos√≥fica)**

#### Execu√ß√£o

```bash
make part1
```

#### O que faz
- Sistema interativo com 6 n√≠veis de perguntas filos√≥ficas
- Identifica 32 correntes filos√≥ficas diferentes
- Recomenda√ß√µes de livros personalizadas (200+ obras catalogadas)

#### Decis√µes de Implementa√ß√£o

**1. Estrutura de Dados Customizada**
```python
class Tree:
    def __init__(self, question, left=None, right=None, leaf_value=None):
        self.question = question
        self.left = left
        self.right = right
        self.leaf_value = leaf_value
```
- **Por que classe pr√≥pria?** Controle total sobre a l√≥gica de navega√ß√£o e visualiza√ß√£o. Permite adicionar m√©todos customizados (ex: `collect_all_nodes()`, `get_depth()`).
- **Alternativa considerada:** Usar `sklearn.tree.DecisionTreeClassifier`, mas n√£o permite constru√ß√£o manual da √°rvore com perguntas textuais.

**2. Hierarquia de 6 N√≠veis**
```
N√≠vel 1: Conhecimento (Racionalismo vs Empirismo)
N√≠vel 2: Realidade (Materialismo vs Idealismo)
N√≠vel 3: √âtica (Deontologia vs Consequencialismo)
N√≠vel 4: Exist√™ncia (Determinismo vs Livre-arb√≠trio)
N√≠vel 5: Pol√≠tica (Individualismo vs Coletivismo)
N√≠vel 6: Est√©tica (Objetividade vs Subjetividade)
```
- **Por que 6 n√≠veis?** 2^6 = 64 folhas poss√≠veis, mas usamos 32 correntes (algumas folhas compartilham ramos). Profundidade equilibra especificidade com usabilidade.
- **Decis√£o de design:** Ordem das perguntas segue progress√£o l√≥gica (fundamentos ‚Üí aplica√ß√µes pr√°ticas).


---

### **Parte 2: Machine Learning (Supervisionado)**

#### Execu√ß√£o Completa

```bash
# Execu√ß√£o de todas os algoritmos:
make part2

# Execu√ß√£o individual dos algoritmos:
make part2-preprocess
make part2-dt
make part2-knn
make part2-svm
```

---

#### **1. Pr√©-processamento (`preprocess.py`)**

##### Decis√µes de Implementa√ß√£o

**A. Tratamento de Valores Nulos**
```python
# Num√©ricos: Mediana (n√£o m√©dia!)
imputer_num = SimpleImputer(strategy='median')
X[numerical_cols] = imputer_num.fit_transform(X[numerical_cols])

# Categ√≥ricos: Moda
imputer_cat = SimpleImputer(strategy='most_frequent')
X[categorical_cols] = imputer_cat.fit_transform(X[categorical_cols])
```
- **Por que mediana e n√£o m√©dia?** 
  - M√©dia √© sens√≠vel a outliers. Se 99 valores s√£o ~10 e 1 valor √© 10.000, a m√©dia ser√° distorcida.
  - Mediana √© robusta: sempre retorna o valor central.
  - **Exemplo real:** Em dados de qualidade de √°gua, um sensor defeituoso pode gerar pH=999. Mediana ignora esse erro.

**B. Label Encoding vs One-Hot Encoding**
```python
# Label Encoding (usado no projeto)
le = LabelEncoder()
X['Soil_Type'] = le.fit_transform(X['Soil_Type'])
# ['loam', 'sandy', 'clay'] ‚Üí [0, 1, 2]

# One-Hot Encoding (comentado, mas dispon√≠vel)
X_encoded = pd.get_dummies(X, columns=['Soil_Type'], drop_first=True)
# Soil_Type_loam | Soil_Type_sandy | Soil_Type_clay
#       1        |        0        |       0
```
- **Por que Label Encoding?**
  - **Decision Trees:** N√£o precisam de One-Hot. √Årvores podem lidar com ordinais (0, 1, 2) diretamente.
  - **KNN/SVM:** Label Encoding funciona quando h√° ordem natural (ex: Pequeno=0, M√©dio=1, Grande=2).
  - **Quando usar One-Hot:** Categorias sem ordem (ex: cores: vermelho, azul, verde). Evita o modelo assumir que "azul" (1) est√° "entre" vermelho (0) e verde (2).
- **Trade-off:** One-Hot aumenta dimensionalidade. 10 categorias ‚Üí 10 colunas. Afeta performance em datasets grandes.

**C. Escalonamento: StandardScaler vs MinMaxScaler**
```python
# StandardScaler (m√©dia=0, desvio=1)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# MinMaxScaler (valores entre 0 e 1) - usado no projeto
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)
```
- **Por que MinMaxScaler?**
  - **KNN:** Dist√¢ncias euclidianas s√£o afetadas por escala. Feature "Renda" (0-100k) dominaria "Idade" (0-100).
  - **SVM:** Kernel RBF usa dist√¢ncias. Features com ranges diferentes quebram a simetria do kernel.
  - **MinMaxScaler vs StandardScaler:** 
    - MinMaxScaler preserva distribui√ß√£o original (boa para dados sem outliers extremos).
    - StandardScaler melhor quando h√° outliers (normaliza pelo desvio padr√£o).
  - **Decision Trees N√ÉO precisam:** √Årvores fazem splits baseados em thresholds relativos (ex: "pH > 7?"). Escala n√£o importa.

**D. Divis√£o Estratificada**
```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2, 
    stratify=y,  # CRUCIAL!
    random_state=42
)
```
- **Por que estratifica√ß√£o?**
  - **Problema:** Dataset com 90% classe A, 10% classe B. Split aleat√≥rio pode gerar treino com 95% A, teste com 85% A.
  - **Solu√ß√£o:** `stratify=y` garante que treino E teste tenham 90% A, 10% B.
  - **Impacto:** Sem estratifica√ß√£o, m√©tricas podem ser enviesadas. Modelo "aprende" distribui√ß√£o diferente da realidade.

**E. Amostragem Aleat√≥ria (10k, 50k, 100k)**
```python
df_sample = df.sample(n=sample_size, random_state=42)
```
- **Por que amostrar?**
  - **Benchmarking:** Comparar performance dos algoritmos em diferentes escalas de dados.
  - **Trade-off tempo vs acur√°cia:** SVM com 100k linhas pode levar horas. 10k linhas permite itera√ß√£o r√°pida.
  - **`random_state=42`:** Reprodutibilidade. Mesma amostra em execu√ß√µes diferentes.

---

#### **2. Treinamento dos Modelos**

##### **Decision Tree (`train_tree.py`)**

```python
dt = DecisionTreeClassifier(
    max_depth=10,              # Limita profundidade
    min_samples_split=20,      # M√≠nimo de amostras para split
    min_samples_leaf=10,       # M√≠nimo de amostras por folha
    random_state=42
)
```

**Decis√µes de Hiperpar√¢metros:**

| Par√¢metro | Valor | Por Que? | Risco se Diferente |
|-----------|-------|----------|-------------------|
| `max_depth=10` | 10 n√≠veis | Profundidade m√©dia para datasets tabulares. Previne overfitting em dados com ru√≠do. | **Muito alto (ex: 50):** √Årvore memoriza treino (overfitting). **Muito baixo (ex: 3):** Underfitting, n√£o captura padr√µes. |
| `min_samples_split=20` | 20 amostras | Evita splits em subconjuntos pequenos (pouco representativos). | **Muito baixo (ex: 2):** √Årvore cria regras espec√≠ficas para poucos exemplos (overfitting). |
| `min_samples_leaf=10` | 10 amostras | Garante que folhas tenham exemplos suficientes para generalizar. | **Muito baixo (ex: 1):** Folhas com 1 exemplo = decorar dataset. |

**Por que Decision Trees s√£o robustas:**
- **N√£o precisam de escalonamento:** Splits baseados em thresholds (ex: "Temperatura > 25¬∞C?").
- **Lidam com n√£o-linearidade:** Capturam intera√ß√µes complexas (ex: "SE temperatura > 30 E umidade < 40 ENT√ÉO...").
- **Interpretabilidade:** Regras leg√≠veis por humanos.
- **Overfitting f√°cil:** Sem regulariza√ß√£o, decoram o treino. Por isso os hiperpar√¢metros acima.

---

##### **KNN (`train_knn.py`)**

```python
knn = KNeighborsClassifier(
    n_neighbors=5,    # K=5 vizinhos
    n_jobs=-1         # Paraleliza√ß√£o (usa todos os cores)
)
```

**Sele√ß√£o do K=5:**
```python
# Testamos K de 1 a 20 e plotamos acur√°cia
k_range = list(range(1, 21))
for k in k_range:
    knn = KNeighborsClassifier(n_neighbors=k)
    # ... treinar e avaliar
# Gr√°fico mostra K=5 como melhor trade-off
```

| K | Comportamento | Por Que N√£o Escolher? |
|---|---------------|----------------------|
| **K=1** | Classifica baseado no vizinho mais pr√≥ximo | **Overfitting:** Sens√≠vel a ru√≠do. Um outlier mislabeled pode quebrar predi√ß√£o. |
| **K=5** | **Balanceado** | Suaviza ru√≠do sem perder granularidade. |
| **K=20** | Classifica baseado em 20 vizinhos | **Underfitting:** Fronteiras de decis√£o muito suaves. Perde detalhes. |

---

##### **SVM (`train_svm.py`)**

```python
svm = SVC(
    kernel='rbf',        # Radial Basis Function (n√£o-linear)
    C=1.0,               # Regulariza√ß√£o
    probability=True,    # Habilita predict_proba() para ROC-AUC
    random_state=42
)
```

**Decis√µes de Hiperpar√¢metros:**

| Par√¢metro | Valor | Por Que? |
|-----------|-------|----------|
| `kernel='rbf'` | Radial Basis Function | **N√£o-linear:** Mapeia dados para espa√ßo de alta dimens√£o onde s√£o linearmente separ√°veis. Alternativas: `'linear'` (mais r√°pido, assume separabilidade linear), `'poly'` (polinomial, caro computacionalmente). |
| `C=1.0` | Penaliza√ß√£o padr√£o | **Trade-off:** C alto ‚Üí Margem estreita (overfitting). C baixo ‚Üí Margem larga (underfitting). 1.0 √© balanceado. |
| `probability=True` | Habilita probabilidades | **Necess√°rio para ROC-AUC:** `predict()` retorna classes (0, 1). `predict_proba()` retorna probabilidades (0.0-1.0). Aumenta tempo de treino (~2x), mas essencial para m√©tricas. |

**PCA Opcional (Redu√ß√£o de Dimensionalidade):**
```python
if use_pca:
    pca = PCA(n_components=2)  # Reduz para 2 dimens√µes
    X_train_pca = pca.fit_transform(X_train_scaled)
```
- **Por que PCA?** SVM √© O(n¬≤ a n¬≥) em n√∫mero de amostras. Com muitas features, treino fica lento. PCA reduz features mantendo vari√¢ncia.
- **Trade-off:** Perda de informa√ß√£o. 2 componentes podem capturar 80% da vari√¢ncia, mas 20% √© perdido.

---

#### **3. M√©tricas de Avalia√ß√£o (`util_metrics.py`)**

```python
metrics = {
    'accuracy': accuracy_score(y_true, y_pred),
    'precision': precision_score(y_true, y_pred, average='macro'),
    'recall': recall_score(y_true, y_pred, average='macro'),
    'f1_score': f1_score(y_true, y_pred, average='macro'),
    'roc_auc': roc_auc_score(y_true, y_prob, multi_class='ovr', average='macro')
}
```

**Por que m√∫ltiplas m√©tricas?**

| M√©trica | O que mede | Quando usar |
|---------|------------|-------------|
| **Acur√°cia** | % de predi√ß√µes corretas | Classes balanceadas. **Cuidado:** 90% acur√°cia em dataset com 90% classe A = modelo in√∫til (prediz sempre A). |
| **Precis√£o** | % de positivos previstos que s√£o realmente positivos | Falsos positivos s√£o caros. Ex: spam (marcar email leg√≠timo como spam). |
| **Recall** | % de positivos reais que foram identificados | Falsos negativos s√£o caros. Ex: diagn√≥stico de c√¢ncer (n√£o detectar doen√ßa). |
| **F1-Score** | M√©dia harm√¥nica de Precis√£o e Recall | Trade-off entre FP e FN. Classes desbalanceadas. |
| **ROC-AUC** | √Årea sob curva ROC (varia de 0 a 1) | Avalia performance em diferentes thresholds. 1.0 = perfeito, 0.5 = aleat√≥rio. |


---


### **Parte 3: Algoritmo Gen√©tico**

#### Execu√ß√£o no terminal:
```bash
make part3
```

#### Decis√µes de implementa√ß√£o:
- **Problema implementado:** Knapsack 0/1 (Problema da Mochila);
- Foi utilizada a semente aleat√≥ria `random.seed(42)` para padronizar a gera√ß√£o de itens;
- A codifica√ß√£o na gera√ß√£o de itens foi feita em uma lista de tuplas, em que o primeiro n√∫mero da tupla armazena o peso do item e o segundo n√∫mero armazena o valor do item (_fitness_). Isso tamb√©m √© imprimido no terminal da seguinte forma:
```
[(1, 1), (3, 4), (2, 3), (1, 2), (5, 7), (1, 1), (1, 4), (2, 1), (5, 4), (5, 7)] 
```

- A codifica√ß√£o dos genes √© feita de forma bin√°ria, com base no √≠ndice da lista de itens do problema. No caso, um gene √© uma lista do tamanho do n√∫mero de itens, em que 1 indica que o item foi selecionado para entrar na mochila e 0 indica que o item n√£o foi selecionado, como pode ser visto a seguir:

```
[1, 0, 0, 0, 0, 0, 0, 0, 0, 1]
```

- O problema foi parametrizado com base nos seguintes par√¢metros e valores padr√£o para execu√ß√£o:

| Par√¢metros | Valores |
|------------|---------|
| N√∫mero de itens | 10 |
| Peso m√°ximo por item | 5 |
| Valor m√°ximo por item | 8 |
| Peso m√°ximo da mochila | 10 |
| Tamanho da popula√ß√£o | 400 |
| N√∫mero de gera√ß√µes | 1000 |
| Taxa inicial de muta√ß√£o | 1% |
| Taxa vari√°vel de muta√ß√£o | 5% | 

- O fitness de um gene √© calculado com base na soma dos valores dos itens no gene quando a soma dos pesos dos itens do gene √© menor ou
igual ao limite de peso da mochila. Caso contr√°rio, o fitness √© zerado.

- A implementa√ß√£o conta com operadores caracter√≠sticos do algoritmo gen√©tico:
  - _Elitismo:_ Permite no c√≥digo com que ma que os dois genes com maior fitness de
  uma gera√ß√£o sejam preservados para a pr√≥xima gera√ß√£o, desde que ambos possuam fitness maior que zero.
  - _Sele√ß√£o de Pais por roleta:_ Cada gene recebe uma porcentagem com base em seu fitness, que dita a chance de que ele se torne pai atrav√©s da roleta viciada (sem contar com o elitismo).
  - _Taxa de muta√ß√£o vari√°vel:_ Ap√≥s 50 gera√ß√µes, a taxa de muta√ß√£o sobe de 1% para 5%, a fim de garantir movimenta√ß√µes bem-vindas na diversidade gen√©tica dos genes dispon√≠veis ap√≥s esse momento.

---

### **Parte 4: Algoritmos de Enxame e Imunes**

#### Execu√ß√£o no terminal:
```bash
# Executar ambos os algoritmos:
make part4

# Executar apenas ACO vs GA:
make part4-aco

# Executar compara√ß√£o completa (CLONALG vs ACO vs GA):
make part4-clonalg
```

#### O que faz:
Esta parte implementa e compara **tr√™s algoritmos bio-inspirados** resolvendo o **Problema da Mochila (Knapsack 0/1)**:

1. **ACO (Ant Colony Optimization)** - Otimiza√ß√£o por Col√¥nia de Formigas
2. **GA (Genetic Algorithm)** - Algoritmo Gen√©tico (da Parte 3)
3. **CLONALG (Clonal Selection Algorithm)** - Sele√ß√£o Clonal (Sistema Imune Artificial)

---

#### **1. ACO - Ant Colony Optimization (`aco.py`)**

##### Como funciona:
Imagine formigas procurando comida. Elas deixam **ferom√¥nios** no caminho, e outras formigas seguem trilhas com mais ferom√¥nio. Com o tempo, o caminho mais curto acumula mais ferom√¥nio (porque as formigas completam o trajeto mais r√°pido).

**No Knapsack:**
- Cada "formiga" constr√≥i uma solu√ß√£o selecionando itens probabilisticamente
- Itens com **maior efici√™ncia (valor/peso)** e **mais ferom√¥nio** t√™m maior chance de serem escolhidos
- Boas solu√ß√µes refor√ßam o ferom√¥nio nos itens selecionados
- Ferom√¥nio evapora com o tempo (evita converg√™ncia prematura)

##### Par√¢metros principais:

| Par√¢metro | Valor | O que faz |
|-----------|-------|-----------|
| `n_ants=30` | 30 formigas | Cada formiga cria uma solu√ß√£o por itera√ß√£o |
| `alpha=1.0` | Peso do ferom√¥nio | Controla influ√™ncia da trilha de ferom√¥nio |
| `beta=2.0` | Peso da heur√≠stica | Controla influ√™ncia da efici√™ncia do item (valor/peso) |
| `rho=0.5` | Taxa de evapora√ß√£o | 50% do ferom√¥nio evapora a cada itera√ß√£o |
| `Q=100` | Quantidade de ferom√¥nio | Quanto ferom√¥nio √© depositado nas solu√ß√µes |

##### Decis√µes de implementa√ß√£o:

**Elitismo no dep√≥sito de ferom√¥nio:**
```python
# Apenas as top 30% solu√ß√µes depositam ferom√¥nio
n_elite = max(1, int(0.3 * len(solutions)))
for sol, val, _ in solutions_sorted[:n_elite]:
    # Deposita ferom√¥nio proporcional ao valor da solu√ß√£o
```
- **Por qu√™** evita que solu√ß√µes ruins "poluam" a trilha de ferom√¥nio
- **Alternativa:** Todas as formigas depositam (converge muito r√°pido)

**Heur√≠stica baseada em efici√™ncia:**
```python
self.heuristic = np.array([item.efficiency for item in items])
# efficiency = value / weight (quanto valor por unidade de peso)
```
- **Por qu√™** guia as formigas para itens "valiosos e leves"
- **Impacto:** Converge ~10x mais r√°pido que sem heur√≠stica

**Resultados esperados:**
- Encontra solu√ß√£o **√≥tima ou pr√≥xima do √≥timo** (valor ~2239)
- Converg√™ncia **r√°pida** (primeiras 10-20 itera√ß√µes)
- Alta **diversidade** de solu√ß√µes (30/30 formigas encontram caminhos diferentes para o mesmo valor)

---

#### **2. CLONALG - Clonal Selection Algorithm (`clonag.py`)**

##### Como funciona:
Inspirado no **sistema imune humano**. Quando um v√≠rus invade o corpo, c√©lulas de defesa (linf√≥citos) que reconhecem o invasor se multiplicam (clonagem) e sofrem muta√ß√µes para melhorar o reconhecimento.

**No Knapsack:**
- **Popula√ß√£o inicial:** 80 solu√ß√µes aleat√≥rias
- **Sele√ß√£o:** Escolhe as 15 melhores solu√ß√µes (maior valor)
- **Clonagem:** Cada solu√ß√£o selecionada gera clones (quanto melhor a solu√ß√£o, mais clones)
- **Hipermuta√ß√£o:** Clones sofrem muta√ß√µes (solu√ß√µes piores mutam mais)
- **Sele√ß√£o clonal:** Clones competem entre si, sobrevivem os melhores
- **Inje√ß√£o de diversidade:** 30 solu√ß√µes aleat√≥rias entram a cada gera√ß√£o

##### Par√¢metros principais:

| Par√¢metro | Valor | O que faz |
|-----------|-------|-----------|
| `pop_size=80` | 80 indiv√≠duos | Tamanho da popula√ß√£o |
| `n_select=15` | 15 selecionados | Quantos ser√£o clonados |
| `beta=1.2` | Fator de clonagem | Controla quantos clones por solu√ß√£o |
| `n_random=30` | 30 aleat√≥rios | Novas solu√ß√µes injetadas por gera√ß√£o |

##### Decis√µes de implementa√ß√£o:

**Taxa de muta√ß√£o adaptativa:**
```python
# Solu√ß√µes piores mutam mais (explora√ß√£o)
# Solu√ß√µes melhores mutam menos (explora√ß√£o fina)
val_norm = val / (max_val + 1e-9)  # Normaliza entre 0 e 1
rate = 0.5 * (1.0 - val_norm * 0.8)  # 0.1 a 0.5
```
- **Por qu√™** solu√ß√µes ruins precisam mudar drasticamente. Solu√ß√µes boas precisam apenas ajustes finos.
- **Impacto:** Evita converg√™ncia prematura (toda popula√ß√£o id√™ntica)

**Hipermuta√ß√£o para indiv√≠duos convergidos:**
```python
# Se uma solu√ß√£o √© muito similar √† melhor (< 5 bits diferentes)
if hamming_distance(sol, best_sol) < 5:
    # Aplica muta√ß√£o muito agressiva (40-60%)
    rate = np.random.uniform(0.4, 0.6)
```
- **Por qu√™** "sacode" a popula√ß√£o quando ela est√° estagnada
- **Problema resolvido:** Vers√£o anterior colapsava para 1/80 solu√ß√µes √∫nicas. Agora mant√©m 56-69/80.

**Sele√ß√£o h√≠brida (50% fitness + 50% diversidade):**
```python
# Metade da popula√ß√£o: melhores por valor
elite = population[:pop_size // 2]

# Outra metade: remove duplicatas exatas
diverse = [solu√ß√µes √∫nicas]
```
- **Por qu√™** balanceia qualidade (n√£o perder boas solu√ß√µes) com diversidade (n√£o decorar)
- **Trade-off:** Pode manter solu√ß√µes sub√≥timas se forem √∫nicas

**Reparo de solu√ß√µes inv√°lidas:**
```python
# Se peso excede capacidade, remove itens de menor efici√™ncia
while weight > capacity:
    # Remove item menos eficiente (menor valor/peso)
```
- **Por qu√™** as muta√ß√µes podem gerar solu√ß√µes que excedem a capacidade da mochila
- **Alternativa:** Penalizar com fitness=0 (desperdi√ßa avalia√ß√µes)

**Resultados esperados:**
- Encontra solu√ß√£o **pr√≥xima do √≥timo** (valor ~2214, 98.9% do √≥timo)
- Converg√™ncia **gradual** (melhora ao longo de 100 gera√ß√µes)
- Boa **diversidade** mantida (56-69/80 solu√ß√µes √∫nicas)

---

#### **3. Compara√ß√£o: ACO vs GA vs CLONALG**

##### Gr√°ficos gerados:

**Figura 1 - Converg√™ncia e M√©dia:**
- Mostra como cada algoritmo encontra solu√ß√µes melhores ao longo do tempo
- ACO converge r√°pido (itera√ß√£o 1-10), GA e CLONALG gradualmente

**Figura 2 - Diversidade e Taxa de Converg√™ncia:**
- **Diversidade:** Quantas solu√ß√µes diferentes existem na popula√ß√£o
  - ACO: ~30/30 (todas diferentes, mesmo valor)
  - CLONALG: ~60/80 (boa diversidade)
  - GA: ~100/100 (m√°xima diversidade)
- **Taxa de converg√™ncia:** Velocidade de melhoria (valor ganho por itera√ß√£o)

**Figura 3 - Efici√™ncia e Compara√ß√£o Final:**
- **Efici√™ncia:** Valor final √∑ tempo de execu√ß√£o (quanto "retorno por segundo")
  - CLONALG: ~475 valor/s (mais r√°pido)
  - ACO: ~230 valor/s
  - GA: ~200 valor/s
- **Qualidade vs Tempo:** Compara valor final e tempo de execu√ß√£o

##### Por que ACO vence?

| M√©trica | ACO | GA | CLONALG |
|---------|-----|-----|---------|
| **Valor final** | 2239 (100%) | ~2100 (93.8%) | 2214 (98.9%) |
| **Tempo** | ~10s | ~10s | ~5s |
| **Converg√™ncia** | R√°pida (10 iter) | Lenta (100 ger) | M√©dia (60 ger) |
| **Diversidade** | Alta (30/30) | Alta (100/100) | M√©dia (60/80) |

**ACO √© melhor porque:**
1. **Heur√≠stica guiada:** Usa efici√™ncia (valor/peso) como "cheiro" inicial
2. **Explora√ß√£o inteligente:** Ferom√¥nio refor√ßa bons caminhos, mas evapora√ß√£o permite explora√ß√£o
3. **Elitismo controlado:** S√≥ 30% depositam ferom√¥nio (evita converg√™ncia prematura)

**Quando usar cada algoritmo:**
- **ACO:** Problemas com **estrutura de grafo** (caminhos, rotas, sequ√™ncias). Converge r√°pido com heur√≠stica boa.
- **GA:** Problemas **sem heur√≠stica √≥bvia**. Gen√©rico, funciona para tudo (mas n√£o √© o melhor em nada).
- **CLONALG:** Problemas que precisam **alta diversidade** (multiobjetivo, paisagens rugosas). R√°pido e eficiente.

---

#### Problema resolvido: Knapsack 0/1

**Configura√ß√£o padr√£o:**
- **50 itens** gerados aleatoriamente (peso: 5-50, valor: 10-100)
- **Capacidade da mochila:** 686 (metade do peso total)
- **Semente aleat√≥ria:** 42 (itens), 100/200/300 (GA/ACO/CLONALG)

**Solu√ß√£o √≥tima encontrada pelo ACO:**
- **Valor:** 2239
- **Peso:** 686/686 (100% da capacidade)
- **Itens selecionados:** 32/50

**Por que n√£o testamos algoritmos exatos (programa√ß√£o din√¢mica)?**
- Knapsack 0/1 tem solu√ß√£o exata O(n√óW), onde n=itens e W=capacidade
- Para n=50, W=686: ~34.300 opera√ß√µes (instant√¢neo)
- **Mas:** Algoritmos exatos n√£o escalam. Com n=10.000, W=100.000: 1 bilh√£o de opera√ß√µes
- **Algoritmos bio-inspirados** escalam melhor (tempo proporcional a popula√ß√£o√ógera√ß√µes, n√£o a capacidade)

---

## Resultados e Compara√ß√µes

### Visualizar Resultados

```bash
make results
```

Este comando exibe:
- **Relat√≥rio comparativo** (`comparison_report.txt`) com m√©tricas de todos os algoritmos
- **Benchmark CSV** (`benchmark_results.csv`) com dados tabulares
- **Matrizes de confus√£o** (`.png`) para an√°lise visual de erros
- **Gr√°fico de sele√ß√£o de K** (KNN) mostrando por que K=5 foi escolhido
- **Visualiza√ß√£o da Decision Tree** (estrutura completa da √°rvore)

### Interpreta√ß√£o dos Resultados

**Compara√ß√£o T√≠pica (Water Quality Dataset):**

| Algoritmo | Acur√°cia Teste | Tempo Treino | Overfitting |
|-----------|----------------|--------------|-------------|
| **Decision Tree** | ~98.7% | ~0.45s | Baixo (0.008%) | 
| **KNN** | ~92.6% | ~0.23s | M√©dio (2.8%) | 
| **SVM** | ~95.0% | ~590s | Baixo (-0.07%) | 

**An√°lise:**
- **Decision Tree:** Melhor acur√°cia e interpretabilidade. R√°pida de treinar. **Escolha ideal para este dataset.**
- **KNN:** Treino r√°pido, mas performance inferior. Overfitting moderado (decora padr√µes locais do treino).
- **SVM:** Boa acur√°cia, mas treino MUITO lento (10 minutos para 100k linhas). Modelo "black box" (dif√≠cil interpretar).

**Por que Decision Tree venceu aqui?**
1. **Dataset tabular com features num√©ricas:** √Årvores s√£o naturalmente adequadas para dados estruturados.
2. **Intera√ß√µes n√£o-lineares:** √Ågua pot√°vel depende de combina√ß√µes (ex: pH alto + Cloro baixo = n√£o pot√°vel).
3. **Dados limpos:** Poucas outliers extremas, ent√£o robustez do KNN n√£o foi necess√°ria.
4. **Interpretabilidade requerida:** Podemos extrair regras (ex: "SE Hardness < 200 E Solids > 20000 ENT√ÉO pot√°vel").

---

## Estrutura de Arquivos Gerados

```
data/processed/
‚îú‚îÄ‚îÄ benchmark_results.csv           # M√©tricas de todos os treinos (Parte 2)
‚îú‚îÄ‚îÄ comparison_report.txt           # Relat√≥rio formatado (Parte 2)
‚îú‚îÄ‚îÄ confusion_matrix_dt_100000.png  # Matriz de confus√£o (Decision Tree)
‚îú‚îÄ‚îÄ confusion_matrix_knn_100000.png # Matriz de confus√£o (KNN)
‚îú‚îÄ‚îÄ confusion_matrix_svm_100000.png # Matriz de confus√£o (SVM)
‚îú‚îÄ‚îÄ decision_tree_visualization_100000.png  # √Årvore completa
‚îú‚îÄ‚îÄ knn_k_selection.png             # Gr√°fico de sele√ß√£o de K
‚îú‚îÄ‚îÄ aco_fig1_convergencia_media.png # ACO vs GA: Converg√™ncia e m√©dia
‚îú‚îÄ‚îÄ aco_fig2_diversidade_feromonios.png # ACO: Diversidade e ferom√¥nios
‚îú‚îÄ‚îÄ aco_fig3_eficiencia_comparacao.png  # ACO vs GA: Efici√™ncia
‚îú‚îÄ‚îÄ fig1_convergencia_media.png     # CLONALG vs ACO vs GA: Converg√™ncia
‚îú‚îÄ‚îÄ fig2_diversidade_taxa.png       # CLONALG vs ACO vs GA: Diversidade
‚îú‚îÄ‚îÄ fig3_eficiencia_comparacao.png  # CLONALG vs ACO vs GA: Efici√™ncia
‚îú‚îÄ‚îÄ X_train.csv                     # Features de treino (n√£o escalonadas)
‚îú‚îÄ‚îÄ X_train_scaled.csv              # Features de treino (escalonadas)
‚îú‚îÄ‚îÄ X_test.csv                      # Features de teste (n√£o escalonadas)
‚îú‚îÄ‚îÄ X_test_scaled.csv               # Features de teste (escalonadas)
‚îú‚îÄ‚îÄ y_train.csv                     # Labels de treino
‚îî‚îÄ‚îÄ y_test.csv                      # Labels de teste
```


---

## Refer√™ncias 

- **"Introduction to Machine Learning with Python"** - Andreas M√ºller & Sarah Guido
  - Cap√≠tulos 2-3: Pr√©-processamento e valida√ß√£o
  - Cap√≠tulo 5: Decision Trees, KNN, SVM
- **"Hands-On Machine Learning"** - Aur√©lien G√©ron
  - Cap√≠tulo 6: Decision Trees e Random Forests
  - Cap√≠tulo 5: SVM e Kernel Trick

### Documenta√ß√£o Oficial
- [scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
- [pandas Documentation](https://pandas.pydata.org/docs/)

---

## Licen√ßa e Autoria

**Disciplina:** Intelig√™ncia Artificial (2025/2)  
**Professor:** Tiago Alves de Oliveira  
**Institui√ß√£o:** Cefet-MG Divin√≥polis
**Alunos:** Jo√£o Pedro Rodrigues Silva e Samuel Silva Gomes

---

## Contato

Para d√∫vidas ou sugest√µes, abra uma issue no reposit√≥rio ou entre em contato com os autores.

